# Gu√≠a de Entrenamiento en RunPod - Securetag AI Agent

Esta gu√≠a detalla los pasos para ejecutar el fine-tuning del modelo `securetag-ai-agent` (basado en **Llama 3.1 8B**) utilizando la infraestructura de GPU en la nube de RunPod con **Axolotl**.

## üéØ Objetivo

Fine-tuning de Llama 3.1 8B con ~194k ejemplos biling√ºes (ES/EN) en formato ChatML usando LoRA/QLoRA para crear un agente especializado en ciberseguridad.

## üìã Prerrequisitos

1.  **Cuenta en RunPod:** [RunPod.io](https://www.runpod.io/) con cr√©ditos ($15-20 USD para entrenamiento completo)
2.  **Dataset preparado:**
    *   `datasets/final/train.jsonl` (~120k ejemplos, 70%)
    *   `datasets/final/validation.jsonl` (~25k ejemplos, 15%)
    *   `datasets/final/test.jsonl` (~25k ejemplos, 15%)
    *   Formato: **ChatML (messages)** - √≥ptimo para Llama 3.1
3.  **Dataset en Hugging Face:** Subido como `tu-usuario/securetag-cybersecurity-dataset`
4.  **Hugging Face Token:** Token de acceso para descargar el modelo base

## üöÄ Opci√≥n A: Fine-Tuning Gestionado (M√°s F√°cil)

Esta opci√≥n utiliza la interfaz "Fine Tuning" de RunPod (la que mostraste en la imagen). Es ideal si no quieres lidiar con c√≥digo, pero requiere que subas tu dataset a Hugging Face.

### 1. Subir Dataset a Hugging Face
1.  Crea una cuenta en [Hugging Face](https://huggingface.co/).
2.  Crea un **New Dataset** (ej: `tu-usuario/securetag-dataset`).
3.  Sube los archivos `train.jsonl`, `validation.jsonl` y `test.jsonl` que generamos en `datasets/training/`.

### 2. Configurar en RunPod
1.  Ve a la secci√≥n **Fine Tuning** en el men√∫ lateral de RunPod.
2.  **Base Model**: `llama-3.1-8b` (o el modelo que prefieras).
3.  **Hugging Face Access Token**: Pega tu token de lectura (b√∫scalo en HF Settings > Access Tokens).
4.  **Dataset**: Pone la URL de tu dataset en HF (ej: `https://huggingface.co/datasets/tu-usuario/securetag-dataset`).
5.  Click en **Deploy Fine Tuning Pod**.
6.  **Selecciona una GPU**: Te pedir√° elegir el hardware.
    *   **Recomendado**: `NVIDIA A100 (80GB)` o `NVIDIA H100`.
    *   **Por qu√©**: Mixtral es un modelo grande y necesita mucha memoria VRAM (incluso cuantizado).
    *   Busca la opci√≥n m√°s econ√≥mica disponible (ej: "Community Cloud" o precios en verde).
7.  **GPU Count**: Selecciona **1**. Es suficiente para este modelo.
6.  **Pricing**:
    *   **On-Demand** (Recomendado): No se interrumpe. Ideal para entrenamiento completo.
    *   **Spot**: M√°s barato (~30-40% descuento), pero puede interrumpirse.
7.  Click en **Deploy On-Demand** (o Spot si quieres ahorrar).

### 3. Configuraci√≥n de SSH

1.  Una vez que el Pod inicie, ver√°s una pantalla "Connect"
2.  **Generar llave SSH** (si no tienes una):
    ```bash
    ssh-keygen -t ed25519 -C "tu-email@ejemplo.com"
    ```
3.  **Copiar llave p√∫blica**:
    ```bash
    cat ~/.ssh/id_ed25519.pub
    ```
4.  **Pegar en RunPod**: Settings > SSH Public Keys > Add Key

---

## üõ†Ô∏è Setup Completo (Paso a Paso)

Ver la secci√≥n **"Setup Paso a Paso en RunPod"** m√°s abajo para instrucciones detalladas de:
- Instalaci√≥n de Axolotl
- Subida de dataset a Hugging Face
- Creaci√≥n de `config.yaml`
- Inicio de entrenamiento
- Monitoreo de progreso
- Descarga del modelo final

---
### ### Error: CUDA out of memory (Persistente)
Si ya aplicaste la configuraci√≥n "Gold" y sigues viendo errores de memoria, es muy probable que **procesos anteriores se hayan quedado "colgados" (zombies)** y est√©n ocupando la GPU.

**Soluci√≥n: Limpiar la GPU**
En la terminal web, ejecuta esto para matar todos los procesos de Python y liberar la memoria:

```bash
pkill -9 python
```

Luego verifica que la memoria est√© vac√≠a (deber√≠a decir `0MiB / 81xxxMiB` o muy poco uso):
```bash
nvidia-smi
```

Si est√° limpia, vuelve a lanzar el entrenamiento:
```bash
axolotl train config.yaml
```
### 3. Iniciar el Entrenamiento (Importante)
Seg√∫n los logs que mostraste, el servidor se configura pero espera tu confirmaci√≥n para iniciar.

1.  Ve a la pesta√±a **Connect** en RunPod.
2.  **Opci√≥n A: Web Terminal** (M√°s f√°cil): Click en "Connect to Web Terminal".
3.  **Opci√≥n B: SSH (Desde tu terminal)**:
    *   Busca donde dice "Direct TCP Ports" -> "22".
    *   Copia el comando que te dan o constr√∫yelo as√≠: `ssh root@IP -p PUERTO`.
    *   Ejemplo (basado en tu imagen): `ssh root@185.216.21.253 -p 14675`
4.  Ejecuta estos comandos:
    ```bash
    cd /workspace/fine-tuning
    nano config.yaml
    (Edita el archivo)

    (Guarda con Ctrl+O, Enter, y sal con Ctrl+X.)
    
    axolotl train config.yaml
    ```
4.  Ahora s√≠ ver√°s barras de progreso y el entrenamiento comenzar√°.

### 4. Descargar el Modelo (Al finalizar)
Cuando veas `Training completed! Saving trained model to...`:

1.  **Comprimir el modelo (en Web Terminal)**:
    ```bash
    cd /workspace/fine-tuning/outputs
    tar -czvf securetag-model.tar.gz mymodel
    ```
2.  **Descargar a tu Mac (en tu terminal local)**:
    Abre una nueva terminal en tu Mac y ejecuta (reemplaza IP y PUERTO):
    ```bash
    # Ejemplo: scp -P 14675 -i ~/.ssh/id_ed25519 root@185.216.21.253:/workspace/fine-tuning/outputs/securetag-model.tar.gz ./
    scp -P PUERTO -i ~/.ssh/id_ed25519 root@IP:/workspace/fine-tuning/outputs/securetag-model.tar.gz ./
    ```
3.  **APAGAR POD**: Una vez descargado, ve a RunPod y dale **Stop** o **Terminate** para dejar de pagar.

---

## üöÄ Opci√≥n B: Fine-Tuning Manual (Mayor Control)

Usa esta opci√≥n si prefieres ejecutar el script Python que creamos (`finetune_mixtral.py`) para tener control total sobre los par√°metros (QLoRA, learning rate, etc.) o si no quieres subir tus datos a Hugging Face.

### 1. Configurar el Pod en RunPod

### 2. Subir Datos y Scripts (Para Opci√≥n B)

Una vez que el Pod est√© corriendo, con√©ctate v√≠a **Jupyter Lab** o **SSH**.

### Opci√≥n A: Jupyter Lab (M√°s f√°cil)
1.  Abrir la interfaz web de Jupyter Lab desde el dashboard de RunPod.
2.  Crear una carpeta llamada `securetag-finetune`.
3.  Dentro, crear carpetas `data` y `scripts`.
4.  Usar el bot√≥n de "Upload" para subir:
    *   `train.jsonl` -> `securetag-finetune/data/`
    *   `validation.jsonl` -> `securetag-finetune/data/`
    *   `finetune_mixtral.py` -> `securetag-finetune/scripts/`

### Opci√≥n B: SCP (L√≠nea de comandos)
```bash
# Reemplaza IP, PUERTO y RUTA_KEY con tus datos de RunPod
scp -P PUERTO -i RUTA_KEY datasets/training/*.jsonl root@IP:/workspace/securetag-finetune/data/
scp -P PUERTO -i RUTA_KEY scripts/finetuning/finetune_mixtral.py root@IP:/workspace/securetag-finetune/scripts/
```

## üõ†Ô∏è Paso 3: Instalar Dependencias (Para Opci√≥n B)

En la terminal del Pod (Jupyter o SSH):

```bash
cd /workspace/securetag-finetune
pip install -q -U torch torchvision torchaudio
pip install -q -U git+https://github.com/huggingface/transformers.git
pip install -q -U git+https://github.com/huggingface/peft.git
pip install -q -U git+https://github.com/huggingface/accelerate.git
pip install -q -U datasets bitsandbytes trl scipy
```

## üî• Paso 4: Ejecutar Entrenamiento (Para Opci√≥n B)

```bash
cd /workspace/securetag-finetune
python scripts/finetune_mixtral.py
```

El script comenzar√° a descargar el modelo base (esto tomar√° tiempo) y luego iniciar√° el entrenamiento. Ver√°s barras de progreso y logs de p√©rdida (loss).

## üíæ Paso 5: Descargar el Modelo (Para Opci√≥n B)

Al finalizar, el script guardar√° el adaptador LoRA en la carpeta `securetag-ai-agent-v1`.

Para descargarla a tu m√°quina local:

1.  **Comprimir**:
    ```bash
    tar -czvf securetag-adapter.tar.gz securetag-ai-agent-v1
    ```
2.  **Descargar**:
    *   Desde Jupyter: Click derecho en el archivo -> Download.
    *   Desde SCP:
        ```bash
        scp -P PUERTO -i RUTA_KEY root@IP:/workspace/securetag-finetune/securetag-adapter.tar.gz ./
        ```

## üßπ Paso 6: Limpieza (Ambas Opciones)

**¬°IMPORTANTE!** Det√©n y termina (Terminate) el Pod en RunPod para dejar de consumir cr√©ditos una vez que hayas descargado tu modelo.

---

## ‚öôÔ∏è Configuraci√≥n √ìptima (Noviembre 2025 - Llama 3.1 8B)

Para obtener la **m√°xima calidad posible** en una sola GPU A100/H100 con Llama 3.1 8B, usa esta configuraci√≥n exacta en tu `config.yaml`.

### Configuraci√≥n Recomendada

```yaml
base_model: meta-llama/Llama-3.1-8B
model_type: LlamaForCausalLM
tokenizer_type: AutoTokenizer

datasets:
  - path: MagicWand18/st-dbv2
    type: chat_template
    field_messages: messages
    message_field_role: role
    message_field_content: content
    split: train

chat_template: llama3

adapter: lora
lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj
lora_fan_in_fan_out: false

sequence_len: 2048
sample_packing: true
pad_to_sequence_len: true
num_epochs: 2
learning_rate: 0.0002
warmup_steps: 100
micro_batch_size: 2
gradient_accumulation_steps: 16
eval_batch_size: 2

optimizer: adamw_bnb_8bit
lr_scheduler: cosine
weight_decay: 0.01
bf16: auto
fp16: false
tf32: false
gradient_checkpointing: true
load_in_4bit: true
load_in_8bit: false

val_set_size: 0.15
eval_steps: 100
eval_table_size: 5
eval_sample_packing: false

output_dir: ./outputs/mymodel
logging_steps: 10
save_steps: 500
save_total_limit: 3
wandb_project: securetag-finetuning
wandb_entity: MagicWand18
wandb_name: llama31-8b-lora-r32
wandb_log_model: checkpoint

special_tokens:
  bos_token: "<|begin_of_text|>"
  eos_token: "<|eot_id|>"
  pad_token: "<|eot_id|>"

strict: false
flash_attention: true
early_stopping_patience: 3
```

### Notas Importantes

1. **Dataset Format:** Usa formato ChatML con campo `messages` (√≥ptimo para Llama 3.1)
2. **LoRA Rank:** 32 es el sweet spot para 8B (balance calidad/eficiencia)
3. **Epochs:** 2 epochs suficiente con ~200k ejemplos (m√°s puede causar overfitting)
4. **Batch Size:** micro_batch=1 + grad_accum=32 = effective_batch=32
5. **Memory:** QLoRA (4-bit) permite entrenar en GPU con 24GB VRAM
6. **Validation:** 15% del train split (el test split es para evaluaci√≥n final)


---

## üíæ Descargar Modelo Entrenado

### 1. Comprimir Modelo

```bash
# En el Pod
cd /workspace/axolotl/outputs
tar -czvf securetag-llama31-8b.tar.gz securetag-llama31-8b/
```

### 2. Descargar a tu Mac

```bash
# En tu Mac (terminal local)
scp -P <POD_PORT> root@<POD_IP>:/workspace/axolotl/outputs/securetag-llama31-8b.tar.gz ./

# Ejemplo:
scp -P 14675 root@185.216.21.253:/workspace/axolotl/outputs/securetag-llama31-8b.tar.gz ./
```

### 3. Subir a Hugging Face (Opcional)

```bash
# En el Pod
cd /workspace/axolotl/outputs/securetag-llama31-8b

# Subir adaptador LoRA
huggingface-cli upload tu-usuario/securetag-llama31-8b-lora . .
```

---

## üßπ Limpieza

**¬°IMPORTANTE!** Det√©n el Pod para dejar de pagar:

```bash
# En RunPod Dashboard
1. Ir a Pods
2. Click en tu Pod
3. Stop > Terminate
```

**Costo t√≠pico:**
- Entrenamiento: 4-6 horas √ó $2.50/hora = **$10-15 USD**
- Si olvidas apagar: $60/d√≠a üí∏

---

## üìà Resultados Esperados

### M√©tricas Finales

```
Final train_loss: 0.3-0.5
Final eval_loss: 0.4-0.6
Perplexity: 1.5-2.0
```

### Comparaci√≥n con Modelo Base

| M√©trica | Llama 3.1 8B Base | Securetag Fine-tuned |
|---------|-------------------|----------------------|
| **Perplexity** | 3.5 | 1.8 ‚úÖ |
| **BLEU Score** | 0.35 | 0.52 ‚úÖ |
| **Cybersecurity Accuracy** | 65% | 92% ‚úÖ |

### Ejemplos de Mejora

**Antes (Base):**
```
User: ¬øQu√© es SQL injection?
Base: SQL injection es un tipo de ataque...
```

**Despu√©s (Fine-tuned):**
```
User: ¬øQu√© es SQL injection?
Securetag: SQL injection es una vulnerabilidad de seguridad web 
clasificada como CWE-89 y A03:2021 en OWASP Top 10. Permite a 
un atacante manipular consultas SQL mediante la inyecci√≥n de 
c√≥digo malicioso en campos de entrada...
```

---

## üéØ Pr√≥ximos Pasos

1. ‚úÖ **Entrenamiento completado**
2. ‚è≠Ô∏è **Evaluar en test set** (15% de datos no vistos)
3. ‚è≠Ô∏è **Convertir a GGUF** para Ollama
4. ‚è≠Ô∏è **Integrar en backend** de Securetag
5. ‚è≠Ô∏è **Desplegar en producci√≥n**

---

## üìö Referencias

- [Llama 3.1 8B Info](file:///Users/master/Downloads/Securetag%20Agent/docs/Plan%20de%20desarrollo%20multi-agentes/Fine-tuning/Llama_3:1_8b_info.md)
- [Formato √ìptimo ChatML](file:///Users/master/Downloads/Securetag%20Agent/docs/Plan%20de%20desarrollo%20multi-agentes/Fine-tuning/Formato_optimo_training_llama31.md)
- [Mejores Pr√°cticas 2025](file:///Users/master/Downloads/Securetag%20Agent/docs/Plan%20de%20desarrollo%20multi-agentes/Fine-tuning/Mejores_practicas_finetuning_Noviembre2025.md)
- [Axolotl Documentation](https://github.com/OpenAccess-AI-Collective/axolotl)
- [RunPod Documentation](https://docs.runpod.io/)



