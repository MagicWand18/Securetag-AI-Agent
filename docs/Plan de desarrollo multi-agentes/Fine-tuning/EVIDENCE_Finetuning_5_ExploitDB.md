# EVIDENCE - Fine-tuning Agent - Iteración 5 (Exploit-DB)

## 1. Resumen Ejecutivo
Se ha completado la **Tarea 10.3: Data Gen - Exploit-DB**, integrando exitosamente el repositorio oficial de Exploit-DB al pipeline de entrenamiento.

Tras iterar sobre varias estrategias (LLM puro, Híbrido), se optó por un **Enfoque Determinista Basado en Plantillas**. Esta decisión estratégica garantiza la integridad absoluta del código de los exploits, elimina alucinaciones, reduce el costo a cero y asegura un volumen masivo de datos de alta calidad para capacidades ofensivas (Red Teaming).

**Estado:** ✅ Completado. Dataset generado y listo para consolidación.

**⚠️ Nota Importante para Agente Supervisor:**
Este dataset **NO** se usará para actualizar el modelo generalista `securetag-v1`. En su lugar, será la base de entrenamiento para un **nuevo modelo independiente especializado** denominado **`securetag-xpl01t`**. Este modelo operará como un microservicio serverless dedicado exclusivamente a tareas ofensivas y desarrollo de exploits. mas informacion en [Plan de desarrollo multi-agentes/Fine-tuning/ROADMAP_Offensive_Model_Training.md](ROADMAP_Offensive_Model_Training.md)

## 2. Estrategia Técnica Implementada

### 2.1 Adquisición y Filtrado de Datos ("Code Only")
Se perfeccionó el proceso de extracción para priorizar la utilidad técnica sobre el volumen bruto.
- **Fuente:** Repositorio oficial `gitlab.com/exploit-database/exploitdb`.
- **Filtro de Verificación:** Solo exploits con `verified="1"`.
- **Filtro de Contenido (Nuevo):** Se implementó un filtro estricto en `extract_exploitdb.py` para descartar documentación y descripciones (`.txt`, `.md`, `.pdf`).
- **Resultado:** Se conservaron **12,718 archivos de código fuente puro** (Python, C, Ruby, Perl, PHP, Go, etc.), descartando ~21,000 archivos de texto que no aportaban valor para la generación de código.

### 2.2 Estrategia de Generación: Determinista con Plantillas
Para resolver problemas de calidad (respuestas vagas de LLMs) y censura (filtros de seguridad en APIs), se desarrolló un motor de generación determinista (`generate_qa_deterministic.py`) que no depende de Inteligencia Artificial.

**Lógica del Algoritmo:**
1.  **Entrada:** Chunk de exploit (Código + Metadata).
2.  **Generación de Preguntas (Templates):** Se generan automáticamente 3 variantes de preguntas por cada exploit para cubrir diferentes intenciones de búsqueda:
    *   *Por Identificador:* "¿Dónde puedo encontrar el exploit para CVE-XXXX-XXXX?"
    *   *Por Título:* "¿Cómo puedo explotar [Nombre del Software]?"
    *   *Por Contexto:* "¿Tienes algún exploit [Tipo] para [Plataforma] relacionado con [Título]?"
3.  **Construcción de Respuesta:** Se inyecta el código literal del exploit en un bloque de código Markdown, detectando y aplicando el resaltado de sintaxis correcto según la extensión del archivo original.

### 2.3 Pipeline Final
El flujo de trabajo quedó consolidado en los siguientes scripts:

1.  **`extract_exploitdb.py`**:
    *   Lee el índice CSV.
    *   Aplica filtros de verificado y extensión de archivo (Code-Only).
    *   Extrae contenido real.
2.  **`process_exploitdb.py`**:
    *   Convierte cada archivo en un "Chunk" atómico (1 Exploit = 1 Chunk).
    *   Preserva la metadata estructurada.
3.  **`generate_qa_deterministic.py` (Core)**:
    *   Motor de generación masiva.
    *   Procesa los 12,718 chunks en < 1 minuto.
    *   Genera el dataset final en formato Q&A compatible con el entrenamiento.

## 3. Resultados y Métricas

| Métrica | Valor | Notas |
| :--- | :--- | :--- |
| **Total Exploits Procesados** | **12,718** | Filtrados solo código ejecutable/compilable. |
| **Total Pares Q&A** | **38,154** | 3 variantes de pregunta por exploit. |
| **Costo de Generación** | **$0.00** | Sin uso de APIs (OpenAI/OpenRouter). |
| **Tiempo de Ejecución** | **< 1 min** | Procesamiento local ultrarrápido. |
| **Calidad del Código** | **100%** | Idéntico al original verificado (Bit-perfect). |

## 4. Justificación del Cambio de Estrategia
Se descartó el uso de LLMs (GPT-4/Grok) para esta tarea específica por las siguientes razones:
1.  **Integridad:** Los LLMs tendían a resumir o modificar el código del exploit, rompiendo su funcionalidad. El enfoque determinista garantiza que el modelo aprenda el exploit exacto.
2.  **Censura:** Incluso modelos "uncensored" presentaban fricción o requerían prompts complejos para generar malware/exploits.
3.  **Eficiencia:** Procesar 33k exploits vía API hubiera costado horas y cientos de dólares. El script Python lo resuelve en segundos gratis.

## 5. Archivos Entregables
- **Script de Generación:** `scripts/finetuning/generate_qa_deterministic.py`
- **Dataset Final:** `datasets/qa_generated/json_exploitdb_deterministic.json`

## 6. Próximos Pasos
El dataset `json_exploitdb_deterministic.json` está listo para ser combinado con el resto de datasets de entrenamiento (OWASP, Mitre, etc.) mediante el script de consolidación.
