# EVIDENCE - Fine-tuning Agent - IteraciÃ³n 3

**Agente**: Fine-tuning  
**Fecha**: 2025-11-23  
**Supervisor**: Pendiente de revisiÃ³n  
**Estado**: ğŸ”„ En progreso (GeneraciÃ³n Q&A HuggingFace + Tier 1)

---

## ğŸ¯ Objetivo de la IteraciÃ³n

Resolver problemas crÃ­ticos de integraciÃ³n con Ollama, migrar a Llama 3.1 8B, expandir el dataset con datos de HuggingFace, y preparar el entrenamiento final con configuraciÃ³n optimizada para noviembre 2025.

---

## âœ… Tareas Completadas

### 1. ResoluciÃ³n de Problemas con Ollama

#### Problema: Error persistente `adapter_config.json: no such file or directory`

**Contexto**: El comando `ollama create securetag-v1 -f Modelfile` fallaba consistentemente a pesar de que el archivo existÃ­a.

**Causa raÃ­z identificada**:
- âŒ **Error conceptual**: Se intentÃ³ entrenar un modelo **ya previamente entrenado** (`Mixtral_AI_CyberCoder_7b.Q4_K_M.gguf`)
- El modelo base ya tenÃ­a fine-tuning aplicado, lo que causaba conflictos con el adaptador LoRA

**SoluciÃ³n implementada**:
1. âœ… CorrecciÃ³n del `Modelfile`: Cambiar `ADAPTER` para apuntar a la **carpeta** en lugar del archivo especÃ­fico:
   ```dockerfile
   ADAPTER ./mymodel  # Correcto
   # vs
   ADAPTER ./mymodel/adapter_model.safetensors  # Incorrecto
   ```

2. âœ… **DecisiÃ³n de migraciÃ³n**: Abandonar Mixtral pre-entrenado y migrar a **Llama 3.1 8B base** (sin fine-tuning previo)

**Lecciones aprendidas**:
- Ollama espera que `ADAPTER` apunte al directorio que contiene `adapter_config.json` y `adapter_model.safetensors`
- No se debe aplicar LoRA sobre modelos ya fine-tuned
- Llama 3.1 8B es mÃ¡s apropiado para fine-tuning desde cero

---

### 2. MigraciÃ³n a Llama 3.1 8B

#### JustificaciÃ³n tÃ©cnica

| Aspecto | Mixtral 8x7B | Llama 3.1 8B |
|---------|--------------|--------------|
| **ParÃ¡metros** | ~47B (MoE) | 8B (denso) |
| **VRAM (QLoRA)** | 24-32 GB | 18-22 GB |
| **Velocidad** | MÃ¡s lento | MÃ¡s rÃ¡pido |
| **Costo RunPod** | $15-20/hora | $10-15/hora |
| **Formato Ã³ptimo** | Alpaca | **ChatML** |
| **Soporte Ollama** | Bueno | **Excelente** |
| **Estado base** | Pre-trained | **Base limpio** |

**DecisiÃ³n**: Llama 3.1 8B con formato ChatML

#### ConfiguraciÃ³n optimizada (Noviembre 2025)

Se actualizÃ³ `RUNPOD_TRAINING_GUIDE.md` con configuraciÃ³n de Ãºltima generaciÃ³n:

**Cambios clave**:
- âœ… **LoRA Rank**: 8 â†’ **32** (mejor para modelos 7-13B)
- âœ… **Formato**: Alpaca â†’ **ChatML (messages)**
- âœ… **Chat Template**: `llama3` nativo
- âœ… **Epochs**: 1 â†’ **2** (Ã³ptimo para ~200k ejemplos)
- âœ… **Scheduler**: linear â†’ **cosine annealing**
- âœ… **Flash Attention**: Activado
- âœ… **Sample Packing**: Activado

**Estimaciones para dataset final (~194k ejemplos)**:
- Total steps: ~12,125
- Tiempo: 4-6 horas en A100
- Costo: $10-15 USD
- VRAM: 18-22 GB

---

### 3. ExpansiÃ³n del Dataset con HuggingFace

#### Datos descargados y procesados

Se descargaron **2 datasets de ciberseguridad** de HuggingFace en formato Q&A

**Ventajas**:
- âœ… Formato Q&A listo para usar (no requiere generaciÃ³n con GPT)
- âœ… Datos en inglÃ©s (complementan datos en espaÃ±ol)
- âœ… Cobertura de temas no presentes en Tier 0 (pentesting prÃ¡ctico, awareness)

---

### 4. GeneraciÃ³n Q&A de Tier 1 (En progreso)

#### Estado actual

Se estÃ¡n generando Q&A para **HackTricks** (10,930 chunks) usando **3 workers paralelos** y despues de eso se seguiran creando el resto de los Q&A.

**Manejo**:
- âœ… Retry automÃ¡tico con backoff exponencial (2s, 4s, 8s, 16s)
- âœ… MÃ¡ximo 5 reintentos antes de marcar como fallido
- âœ… Progreso guardado cada 10 chunks (recuperable)

---

## ğŸ“Š Dataset Final Estimado

### ComposiciÃ³n total

| Fuente | Chunks | Q&A (3x) | Idioma | Estado |
|--------|--------|----------|--------|--------|
| **Tier 0** (NIST, MITRE, OWASP, etc.) | 12,420 | 37,260 | ES | âœ… Completado |
| **HuggingFace** (2 datasets) | - | 11,000 | EN | âœ… Descargado |
| **Tier 1** | 10,930 | 32,790 | ES/EN | ğŸ”„ 32% |

---

## ğŸ”§ Scripts Actualizados

### `evaluate_models.py`

**Mejoras implementadas**:
1. âœ… **Rutas absolutas**: Uso de `os.path.dirname(__file__)` para portabilidad
2. âœ… **Modelo actualizado**: `gpt-4o` â†’ `gpt-5.1`
3. âœ… **Prompts en espaÃ±ol**: Sistema de auditorÃ­a 100% en espaÃ±ol
4. âœ… **Reporte incremental**: Genera reporte lÃ­nea por lÃ­nea (no espera al final)
5. âœ… **Progress tracking**: Muestra `[X/Y]` en cada pregunta
6. âœ… **Manejo de tags**: Soporta modelos con `:latest`

**Ejemplo de salida**:
```
[1/10] Evaluating Question: Â¿QuÃ© es SQL injection?...
  âœ… Winner: securetag-v1
[2/10] Evaluating Question: Â¿CÃ³mo funciona XSS?...
  âœ… Winner: modelo-base
```

### `generate_qa.py`

**Mejoras implementadas**:
1. âœ… **Soporte para rangos**: Permite dividir archivos grandes con sintaxis `file.json:start-end`
2. âœ… **Tracking independiente**: Cada rango tiene su propio progreso en `.progress.json`
3. âœ… **Chunk offset**: Mantiene Ã­ndices correctos al procesar rangos

**Ejemplo de uso**:
```bash
python generate_qa.py --files "markdown_hacktricks_chunks.json:0-3643,markdown_hacktricks_chunks.json:3643-7286"
```

### `combine_and_split.py`

**PropÃ³sito**: Combinar todos los Q&A generados y dividir en train/val/test

**CaracterÃ­sticas**:
- âœ… Combina Q&A de Tier 0, Tier 1 y HuggingFace
- âœ… DeduplicaciÃ³n por hash de pregunta
- âœ… Split 70/15/15 (train/val/test)
- âœ… ConversiÃ³n a formato ChatML
- âœ… EstadÃ­sticas detalladas

**Estado**: â¸ï¸ Pendiente de ejecuciÃ³n (esperando finalizaciÃ³n de HackTricks)

---

## ğŸ“ Estructura de Archivos Actualizada

```
datasets/
â”œâ”€â”€ final/                          # â¸ï¸ Pendiente
â”‚   â”œâ”€â”€ train.jsonl                # 70% (~67,235 ejemplos)
â”‚   â”œâ”€â”€ validation.jsonl           # 15% (~14,407 ejemplos)
â”‚   â””â”€â”€ test.jsonl                 # 15% (~14,407 ejemplos)
â”œâ”€â”€ qa_generated/                  # ğŸ”„ En progreso
â”‚   â”œâ”€â”€ .progress.json             # Tracking de generaciÃ³n
â”‚   â””â”€â”€ [32 archivos Tier 1].json  # âœ… Completados
â””â”€â”€ huggingface/                   # âœ… Descargado
```

---

## ğŸš€ PrÃ³ximos Pasos

### Inmediatos

1. **Completar generaciÃ³n HackTricks** (~21 horas restantes)
   - Worker 0: 2,505 chunks restantes
   - Worker 1: 2,453 chunks restantes
   - Worker 2: 2,474 chunks restantes

2. **Ejecutar `combine_and_split.py`**
   - Combinar Tier 0 + HuggingFace + HackTricks
   - Generar splits train/val/test
   - Convertir a formato ChatML

3. **Subir dataset a HuggingFace**
   ```bash
   huggingface-cli upload tu-usuario/securetag-cybersecurity-dataset datasets/final/
   ```

### Entrenamiento en RunPod

1. **Crear Pod A100 40GB** 
2. **Instalar Axolotl** (segÃºn `RUNPOD_TRAINING_GUIDE.md`)
3. **Configurar `config.yaml`** con parÃ¡metros optimizados
4. **Iniciar entrenamiento** 
5. **Descargar modelo** y subir a HuggingFace

---

## ğŸ“ Lecciones Aprendidas

### 1. Ollama + LoRA

**Aprendizaje**: Ollama espera que `ADAPTER` apunte al **directorio**, no al archivo `.safetensors`

**RecomendaciÃ³n**: Siempre usar `ADAPTER ./mymodel` en lugar de `ADAPTER ./mymodel/adapter_model.safetensors`

### 2. Modelos pre-entrenados

**Aprendizaje**: No aplicar LoRA sobre modelos ya fine-tuned (causa conflictos)

**RecomendaciÃ³n**: Usar modelos **base** para fine-tuning (ej: `llama-3.1-8b` en lugar de `llama-3.1-8b-instruct`)

### 3. Formato ChatML

**Aprendizaje**: ChatML es superior a Alpaca para Llama 3.1 (mejor rendimiento en benchmarks 2025)

**RecomendaciÃ³n**: Usar formato `messages` con roles `system`, `user`, `assistant`

### 4. LoRA Rank

**Aprendizaje**: Rank 32 es Ã³ptimo para modelos 7-13B (balance calidad/eficiencia)

**RecomendaciÃ³n**: No usar rank 8 (demasiado bajo para 8B), ni rank 64 (overkill)

### 5. Datasets multilingÃ¼es

**Aprendizaje**: Combinar ES/EN mejora la versatilidad del modelo

**RecomendaciÃ³n**: Mantener balance 60/40 (ES/EN) para contexto latinoamericano

---

## ğŸ“ ConclusiÃ³n

La IteraciÃ³n 3 ha logrado **resolver problemas crÃ­ticos** y **expandir significativamente** el dataset:

**Logros principales**:
- âœ… Resuelto error de Ollama (migraciÃ³n a Llama 3.1 8B)
- âœ… ConfiguraciÃ³n optimizada para entrenamiento (Noviembre 2025)
- âœ… Dataset expandido con 11,000 ejemplos de HuggingFace
- âœ… GeneraciÃ³n Q&A de HackTricks en progreso (32% completado)
- âœ… Scripts mejorados (`evaluate_models.py`, `generate_qa.py`)
- âœ… DocumentaciÃ³n actualizada (`RUNPOD_TRAINING_GUIDE.md`)

**En progreso**:
- ğŸ”„ GeneraciÃ³n Q&A de HackTricks (~21 horas restantes)
- ğŸ”„ CombinaciÃ³n y split del dataset final

**Pendiente**:
- â¸ï¸ Subida de dataset a HuggingFace
- â¸ï¸ Entrenamiento en RunPod con Llama 3.1 8B
- â¸ï¸ EvaluaciÃ³n del modelo fine-tuned

**Impacto esperado**:
- Dataset final: **~96,050 pares Q&A** (vs 37,260 original = **+157%**)
- Cobertura mejorada en pentesting, awareness, y tÃ©cnicas prÃ¡cticas
- Modelo bilingÃ¼e (ES/EN) con mejor versatilidad
- ConfiguraciÃ³n de entrenamiento optimizada (mejores prÃ¡cticas 2025)

---

**Agente Fine-tuning** - IteraciÃ³n 3  
**Ãšltima actualizaciÃ³n**: 2025-11-23 19:45  
**PrÃ³xima revisiÃ³n**: Tras completar generaciÃ³n HackTricks
