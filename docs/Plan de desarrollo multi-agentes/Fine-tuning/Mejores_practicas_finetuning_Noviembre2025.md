# Mejores Pr√°cticas de Fine-tuning - Noviembre 2025

## 1. Train/Validation/Test Split: ¬ø2 o 3 Partes?

### Split de 2 Partes (Train/Validation)

```
Train: 80-85%
Validation: 15-20%
```

**Cu√°ndo usar:**
- ‚úÖ Dataset peque√±o (<50k ejemplos)
- ‚úÖ Recursos computacionales limitados
- ‚úÖ Solo necesitas monitorear overfitting
- ‚úÖ No planeas publicar resultados acad√©micos

**Ventajas:**
- M√°s datos para entrenamiento
- M√°s simple de implementar
- Menos overhead computacional

**Desventajas:**
- ‚ùå Riesgo de "data leakage" si usas validation para decisiones finales
- ‚ùå No tienes evaluaci√≥n completamente imparcial

### Split de 3 Partes (Train/Validation/Test) ‚≠ê **RECOMENDADO**

```
Train: 70-80%
Validation: 10-15%
Test: 10-15%
```

**Cu√°ndo usar:**
- ‚úÖ Dataset grande (>100k ejemplos) ‚Üê **Tu caso**
- ‚úÖ Quieres evaluaci√≥n imparcial final
- ‚úÖ Vas a comparar m√∫ltiples modelos
- ‚úÖ Necesitas reportar m√©tricas confiables

**Ventajas:**
- ‚úÖ Evaluaci√≥n completamente imparcial
- ‚úÖ Previene overfitting al validation set
- ‚úÖ Permite comparaci√≥n justa entre modelos
- ‚úÖ Est√°ndar de la industria en 2025

**Desventajas:**
- Menos datos para entrenamiento
- M√°s complejo de implementar

---

## Ratios Recomendados (Noviembre 2025)

### Para Datasets Grandes (>100k ejemplos)

**Opci√≥n 1: 70-15-15** ‚≠ê **M√ÅS RECOMENDADO**
```
Train:      70% (~140,000 ejemplos)
Validation: 15% (~30,000 ejemplos)
Test:       15% (~30,000 ejemplos)
```

**Ventajas:**
- Balance √≥ptimo seg√∫n investigaci√≥n 2025
- Validation set suficientemente grande para detectar overfitting
- Test set robusto para evaluaci√≥n final

**Opci√≥n 2: 80-10-10**
```
Train:      80% (~160,000 ejemplos)
Validation: 10% (~20,000 ejemplos)
Test:       10% (~20,000 ejemplos)
```

**Ventajas:**
- M√°s datos para entrenamiento
- Validation/test sets a√∫n representativos

### Para Datasets Medianos (50-100k ejemplos)

**Recomendado: 80-10-10**

### Para Datasets Peque√±os (<50k ejemplos)

**Recomendado: 85-15 (sin test)** o **K-Fold Cross-Validation**

---

## ¬øQui√©n Define Estos Ratios?

### Fuentes Autorizadas (Noviembre 2025)

1. **OpenAI** - Recomienda 80-10-10 en su documentaci√≥n oficial
2. **Meta (Llama Team)** - Usa 70-15-15 en Llama Cookbook
3. **Hugging Face** - Recomienda 80-10-10 para datasets >100k
4. **Papers de Investigaci√≥n** - Consenso en 70-15-15 o 80-10-10

### Evoluci√≥n Hist√≥rica

| A√±o | Recomendaci√≥n | Raz√≥n |
|-----|---------------|-------|
| **2020** | 60-20-20 | Datasets m√°s peque√±os |
| **2022** | 70-15-15 | Datasets medianos |
| **2025** | 70-15-15 o 80-10-10 | Datasets grandes, mejores t√©cnicas |

**Tendencia 2025:** Con datasets m√°s grandes y t√©cnicas como LoRA, se puede usar m√°s datos para training sin riesgo de overfitting.

---

## Prop√≥sito de Cada Split

### 1. Training Set (70-80%)

**Prop√≥sito:**
- Entrenar el modelo
- Ajustar pesos y par√°metros
- Aprender patrones del dominio

**Uso:**
- Se usa en cada epoch
- El modelo "ve" estos datos m√∫ltiples veces
- Aqu√≠ ocurre el aprendizaje real

### 2. Validation Set (10-15%)

**Prop√≥sito:**
- Monitorear overfitting durante entrenamiento
- Ajustar hiperpar√°metros (learning rate, epochs, etc.)
- Decidir cu√°ndo detener el entrenamiento (early stopping)
- Seleccionar el mejor checkpoint

**Uso:**
- Se eval√∫a despu√©s de cada epoch
- **NO se usa para entrenar**
- Gu√≠a las decisiones durante el proceso
- Puede verse m√∫ltiples veces (para diferentes hiperpar√°metros)

**‚ö†Ô∏è Riesgo:** Si usas validation para muchas decisiones, puedes "sobreajustar" a este set.

### 3. Test Set (10-15%)

**Prop√≥sito:**
- Evaluaci√≥n final completamente imparcial
- Reportar m√©tricas reales del modelo
- Comparar con otros modelos
- Validar que no hay overfitting

**Uso:**
- **SE USA SOLO UNA VEZ** al final
- **NUNCA** se usa durante entrenamiento
- **NUNCA** influye en decisiones de hiperpar√°metros
- Datos completamente "unseen"

**üéØ Regla de oro:** El test set es sagrado, solo se toca al final.

---

## Mejores Pr√°cticas Espec√≠ficas para Llama 3.1 8B

### Informaci√≥n Clave del Modelo

Seg√∫n tu documento `Llama 3.1 8b info.md`:

**Arquitectura:**
- Context length: **131,072 tokens** (128k)
- Embedding dimension: 4,096
- Attention heads: 32
- Layers: 32
- Vocab size: 128,256

**Template:**
```
<|start_header_id|>system<|end_header_id|>
{system_prompt}<|eot_id|>
<|start_header_id|>user<|end_header_id|>
{user_message}<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>
{assistant_response}<|eot_id|>
```

**Stop tokens:**
- `<|start_header_id|>`
- `<|end_header_id|>`
- `<|eot_id|>`

### Hiperpar√°metros Recomendados (Noviembre 2025)

#### Para LoRA (Recomendado para Llama 3.1 8B)

```yaml
# LoRA Configuration
lora_r: 16-64              # Rank (empieza con 32)
lora_alpha: 32-128         # Alpha (2x el rank)
lora_dropout: 0.05-0.1     # Dropout
lora_target_modules:       # M√≥dulos a ajustar
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj

# Training
num_epochs: 1-3            # 1-2 usualmente suficiente
learning_rate: 1e-4 to 2e-4  # Empieza con 2e-4
warmup_steps: 100-500      # 5-10% del total
batch_size: 1-4            # Depende de GPU
gradient_accumulation: 32  # Para simular batch m√°s grande
max_seq_length: 2048-4096  # Llama 3.1 soporta hasta 128k

# Optimization
optimizer: adamw_bnb_8bit  # 8-bit AdamW (ahorra memoria)
scheduler: cosine          # Cosine annealing
weight_decay: 0.01         # Regularizaci√≥n

# Memory Optimization
bf16: true                 # BFloat16 (mejor que FP16)
gradient_checkpointing: true
load_in_4bit: true         # QLoRA
```

#### Configuraci√≥n Espec√≠fica para Tu Dataset

```yaml
# Dataset
dataset_size: ~200,000 ejemplos
train_size: 140,000 (70%)
val_size: 30,000 (15%)
test_size: 30,000 (15%)

# Training
num_epochs: 2              # Con 200k ejemplos, 2 epochs suficiente
learning_rate: 2e-4        # Est√°ndar para LoRA
warmup_ratio: 0.05         # 5% warmup
max_steps: ~8,750          # 140k / (batch_size * grad_accum)

# Evaluation
eval_steps: 100            # Evaluar cada 100 steps
save_steps: 500            # Guardar checkpoint cada 500 steps
logging_steps: 10          # Log cada 10 steps
```

### LoRA vs Full Fine-tuning

| Aspecto | LoRA | Full Fine-tuning |
|---------|------|------------------|
| **Par√°metros entrenables** | ~0.1-1% | 100% |
| **Memoria requerida** | ~8-12 GB | ~40-60 GB |
| **Tiempo de entrenamiento** | 4-6 horas | 12-20 horas |
| **Calidad** | 95-98% del full | 100% |
| **Costo RunPod** | $10-15 | $40-60 |
| **Recomendado para** | ‚úÖ Tu caso | Datasets >1M |

**Recomendaci√≥n:** Usa **LoRA** para Llama 3.1 8B con tu dataset.

---

## Mejores Pr√°cticas Generales (Noviembre 2025)

### 1. Calidad de Datos ‚≠ê **M√ÅS IMPORTANTE**

```python
# Checklist de calidad
‚úÖ Datos limpios (sin duplicados)
‚úÖ Formato consistente
‚úÖ Distribuci√≥n balanceada
‚úÖ Longitud apropiada (300-2000 tokens por ejemplo)
‚úÖ Idioma consistente (o mezcla intencional)
‚úÖ Metadata preservada
```

### 2. Prevenci√≥n de Overfitting

**T√©cnicas recomendadas:**
- ‚úÖ Early stopping (monitorear validation loss)
- ‚úÖ Dropout en LoRA (0.05-0.1)
- ‚úÖ Weight decay (0.01)
- ‚úÖ Gradient clipping (1.0)
- ‚úÖ Pocos epochs (1-3)

**Se√±ales de overfitting:**
```
Epoch 1: train_loss=0.8, val_loss=0.9  ‚úÖ OK
Epoch 2: train_loss=0.5, val_loss=0.7  ‚úÖ OK
Epoch 3: train_loss=0.3, val_loss=0.8  ‚ö†Ô∏è Overfitting!
```

### 3. Monitoreo Durante Entrenamiento

**M√©tricas clave:**
```python
# Cada epoch, monitorear:
- train_loss        # Debe bajar consistentemente
- val_loss          # Debe bajar (si sube = overfitting)
- perplexity        # Debe bajar
- learning_rate     # Debe seguir scheduler
- grad_norm         # Debe ser estable (<1.0)
```

### 4. Evaluaci√≥n Cualitativa

**No solo m√©tricas cuantitativas:**
- ‚úÖ Probar con ejemplos reales
- ‚úÖ Revisar respuestas manualmente
- ‚úÖ Comparar con modelo base
- ‚úÖ A/B testing con usuarios

### 5. Version Control

```bash
# Versionar TODO
‚úÖ Dataset (con hash)
‚úÖ Config de entrenamiento
‚úÖ Checkpoints
‚úÖ M√©tricas de evaluaci√≥n
‚úÖ C√≥digo de preprocessing
```

---

## Configuraci√≥n Recomendada para Tu Proyecto

### Opci√≥n 1: Conservadora (Recomendada)

```yaml
# Dataset Split
train: 70% (140,000 ejemplos)
validation: 15% (30,000 ejemplos)
test: 15% (30,000 ejemplos)

# LoRA Config
lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
target_modules: [q_proj, v_proj, k_proj, o_proj, gate_proj, down_proj, up_proj]

# Training
num_epochs: 2
learning_rate: 2e-4
warmup_steps: 100
batch_size: 1
gradient_accumulation: 32
max_seq_length: 2048

# Optimization
optimizer: adamw_bnb_8bit
bf16: true
gradient_checkpointing: true
load_in_4bit: true
```

**Tiempo estimado:** 4-6 horas
**Costo estimado:** $10-15 USD

### Opci√≥n 2: Agresiva (M√°s datos para training)

```yaml
# Dataset Split
train: 80% (160,000 ejemplos)
validation: 10% (20,000 ejemplos)
test: 10% (20,000 ejemplos)

# Resto igual que Opci√≥n 1
```

**Ventaja:** M√°s datos para aprender
**Riesgo:** Validation set m√°s peque√±o

---

## Recomendaci√≥n Final

### Para Tu Proyecto (200k ejemplos)

**Split recomendado: 70-15-15** ‚≠ê

**Razones:**
1. ‚úÖ Dataset suficientemente grande
2. ‚úÖ Validation set robusto (30k ejemplos)
3. ‚úÖ Test set para evaluaci√≥n imparcial
4. ‚úÖ Est√°ndar de la industria 2025
5. ‚úÖ Permite comparaci√≥n con otros modelos

**Configuraci√≥n:**
```python
{
  "train_size": 0.70,      # 140,000 ejemplos
  "validation_size": 0.15, # 30,000 ejemplos
  "test_size": 0.15,       # 30,000 ejemplos
  "shuffle": True,
  "stratify": "language",  # Mantener proporci√≥n ES/EN
  "random_seed": 42
}
```

### Pr√≥ximos Pasos

1. ‚úÖ Terminar generaci√≥n de Q&A (workers corriendo)
2. ‚úÖ Convertir Fenrir + Trendyol a formato Alpaca
3. ‚úÖ Combinar todos los datasets
4. ‚úÖ Split 70-15-15 con stratify por idioma
5. ‚úÖ Subir a Hugging Face
6. ‚úÖ Fine-tuning en RunPod con LoRA
7. ‚úÖ Evaluar en test set
8. ‚úÖ Comparar con modelo base

**Tiempo total estimado:** 24-30 horas (incluyendo generaci√≥n Q&A)
**Costo total estimado:** $161 (Q&A) + $15 (fine-tuning) = **$176 USD**
