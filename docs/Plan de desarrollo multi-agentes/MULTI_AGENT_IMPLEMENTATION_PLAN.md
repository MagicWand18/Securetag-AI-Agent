# Plan de Implementaci√≥n Multi-Agente para Securetag SaaS

Este documento define la ruta de trabajo para convertir Securetag Agent en un SaaS robusto, dise√±ado para ser ejecutado por m√∫ltiples agentes de IA en paralelo.

## üö¶ Gu√≠a de Ejecuci√≥n y Estatus Actual

Para saber qu√© agente ejecutar, consulta esta tabla din√°mica. El **Agente Supervisor** actualizar√° esta secci√≥n.

| Agente | Estatus Actual | ¬øPuede Ejecutarse? | Dependencia |
| :--- | :--- | :--- | :--- |
| **Supervisor** | üü¢ **Activo** | ‚úÖ **SI** | N/A |
| **Infra** | üü¢ **Activo** | ‚úÖ **SI** | Deploy scripts listos. Siguiente: Integraci√≥n DO+RunPod |
| **Server** | ‚úÖ **Completado** | ‚è∏Ô∏è **Standby** | Auth implementado. Todas las tareas completadas |
| **Worker** | ‚úÖ **Completado** | ‚è∏Ô∏è **Standby** | LLM integrado. Todas las tareas completadas |
| **Fine-tuning** | ‚úÖ **Completado** | ‚è∏Ô∏è **Standby** | Modelo `securetag-v1` entrenado |

> **Estado Actual (Iteraci√≥n 10 - 2025-12-01)**:
> - **Infra Agent**: ‚úÖ CI/CD y Scripts de Despliegue (DO/RunPod) completados.
> - **Fine-tuning Agent**: ‚úÖ Modelo `securetag-v1` (Llama 3.1 8B) entrenado y validado
> - **Worker Agent**: ‚úÖ LLM Client integrado con an√°lisis autom√°tico High/Critical
> - **Server Agent**: ‚úÖ Autenticaci√≥n y Multi-tenancy implementados

> **Recomendaci√≥n**: Priorizar **Infra Agent** para conectar entornos de producci√≥n (DigitalOcean + RunPod).

## üéØ Objetivo General
Transformar el agente de ciberseguridad (CLI) en una API SaaS multi-tenant, resiliente y escalable, con soporte para herramientas externas (Semgrep, etc.), ejecuci√≥n en contenedores Docker, y generaci√≥n de datasets para fine-tuning de LLMs.

## üèóÔ∏è Arquitectura y Componentes
El sistema se compone de tres pilares principales que pueden evolucionar en paralelo:

1.  **API Server (App)**: Gestiona endpoints, autenticaci√≥n, y orquestaci√≥n de tareas (productor).
2.  **Worker**: Consume tareas, ejecuta herramientas (Semgrep, Nuclei, etc.) y reporta resultados (consumidor).
3.  **Base de Datos (PostgreSQL)**: Fuente √∫nica de verdad para tareas, resultados y logs.
4.  **LLM Service**: Modelo fine-tuned `securetag-v1` en Ollama para an√°lisis de hallazgos.

## ü§ñ Roles de Agentes y Paralelizaci√≥n
Para maximizar la eficiencia, el trabajo se divide en "Tracks" independientes que pueden ser asignados a diferentes agentes.

### üü¢ Track 1: Backend & API (Agente "Server")
**Objetivo**: Migrar la API a una arquitectura 100% Database-Centric y robustecer los endpoints.

*   **Tarea 1.1: Eliminaci√≥n de Dependencia de Archivos (DB-Only)** [x]
    *   **Contexto**: Actualmente `src/server/index.ts` y `routes/codeaudit.ts` leen `tasks.json` si falla la BD o como fallback.
    *   **Acci√≥n**:
        *   Refactorizar `GET /scans/{id}` para leer **exclusivamente** de `securetag.task` y `securetag.scan_result`.
        *   Refactorizar `GET /codeaudit/index` y `latest` para usar `SELECT` SQL.
        *   Eliminar l√≥gica de lectura/escritura en `tasks.json` y `results.json`.
        *   Manejar errores: Si la BD falla, devolver 503 (Service Unavailable), no caer en archivos locales.
    *   **Archivos clave**: `src/server/index.ts`, `src/server/routes/codeaudit.ts`.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 1)

*   **Tarea 1.2: Health Checks y Gating** [x]
    *   **Acci√≥n**:
        *   Implementar `GET /healthz/db` que verifique conexi√≥n a PG.
        *   En `POST /codeaudit/upload` y `POST /scans/web`, verificar conexi√≥n antes de aceptar. Si falla, retornar 503 inmediato.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 2)
    *   **Evidencia**: `EVIDENCE_Server_2_20251119.md`

*   **Tarea 1.3: Autenticaci√≥n y Multi-tenancy** [x]
    *   **Contexto**: La API requer√≠a autenticaci√≥n robusta para soportar m√∫ltiples tenants de forma segura.
    *   **Objetivo**: Implementar sistema de API Keys para proteger los endpoints y asegurar aislamiento de datos por tenant.
    *   **Acciones completadas**:
        1.  **Modelo de Datos**:
            *   ‚úÖ Creada tabla `api_key` con foreign key a `tenant`.
        2.  **Middleware de Autenticaci√≥n**:
            *   ‚úÖ Implementado middleware que valida `X-API-Key`.
            *   ‚úÖ Inyecta `tenant_id` en el contexto de la solicitud.
        3.  **Aislamiento**:
            *   ‚úÖ Todas las consultas a BD filtran por `tenant_id` autenticado.
    *   **Criterios de √©xito**:
        *   ‚úÖ Endpoints protegidos rechazan solicitudes sin credenciales (401).
        *   ‚úÖ Datos aislados por tenant (queries verificadas).
        *   ‚úÖ Pruebas de integraci√≥n con m√∫ltiples tenants.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 3)
    *   **Evidencia**: `EVIDENCE_Server_3_20251128.md`

### üîµ Track 2: Worker & Ejecuci√≥n (Agente "Worker")
**Objetivo**: Mejorar la resiliencia, observabilidad y capacidad del Worker.

*   **Tarea 2.1: Resiliencia y Retries** [x]
    *   **Contexto**: El worker falla si la API no responde.
    *   **Acci√≥n**:
        *   Implementar l√≥gica de reintento exponencial en `src/worker/entrypoint.ts` para las llamadas a `/queue/next` y `/queue/result`.
        *   Manejar c√≥digos 503 del servidor esperando antes de reintentar.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 1)

*   **Tarea 2.2: Estados Avanzados y Heartbeats** [x]
    *   **Acci√≥n**:
        *   Implementar "latidos" peri√≥dicos (cada 30-60s) a la BD (`worker_heartbeat` table).
        *   Soportar estados: `retrying`, `failed` (con raz√≥n), `timeout`.
        *   Implementar timeout configurable por tipo de tarea.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 2)
    *   **Evidencia**: `EVIDENCE_Worker_2_20251119.md`

*   **Tarea 2.3: Logging para Fine-Tuning (Data Gen)** [x]
    *   **Contexto**: Necesitamos datos para entrenar al LLM.
    *   **Acci√≥n**:
        *   Asegurar que **toda** interacci√≥n con herramientas (stdout, stderr, exit code, prompt generado, respuesta del modelo) se guarde en `tool_execution` y tablas de auditor√≠a.
        *   Estandarizar el formato JSON de `metrics_json` en `tool_execution` para incluir tokens usados, tiempo de inferencia, etc.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 1)

*   **Tarea 2.4: Integraci√≥n con LLM Remoto** [x]
    *   **Contexto**: El worker necesita capacidad de an√°lisis inteligente de hallazgos.
    *   **Acci√≥n**:
        *   Implementar clase `LLMClient` que consuma la API de Ollama.
        *   Configurar para usar el modelo `securetag-v1` (Llama 3.1 8B fine-tuned).
        *   En `TaskExecutor`, despu√©s de Semgrep, enviar hallazgos High/Critical al LLM.
        *   Guardar an√°lisis ("Triage: True Positive/False Positive", "Recomendaci√≥n") en la base de datos.
        *   Manejar timeouts o fallos del LLM sin colgar el worker.
    *   **Entregables**:
        *   `src/worker/LLMClient.ts`
        *   Actualizaci√≥n de `TaskExecutor` para usar `securetag-v1`
        *   Tests unitarios del cliente LLM
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 3)
    *   **Evidencia**: `EVIDENCE_Worker_3_20251127.md`
    *   **Pruebas**: `test/test_llm_client.mjs` ejecutado exitosamente

### üü† Track 3: Infraestructura & DevOps (Agente "Infra")
**Objetivo**: Orquestaci√≥n local con Docker y preparaci√≥n para despliegue.

*   **Tarea 3.1: Docker Compose y Red** [x]
    *   **Acci√≥n**:
        *   Crear `docker-compose.yml` en la ra√≠z que levante:
            *   `postgres` (con script de init para esquema).
            *   `securetag-app` (construido desde `docker/app/Dockerfile`).
            *   `securetag-worker` (construido desde `docker/worker/Dockerfile`).
            *   `ollama` (opcional, o conectar a host).
        *   Configurar red `securetag-net`.
        *   Definir vol√∫menes persistentes para DB y datos de tenants.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 1)

*   **Tarea 3.2: Scripts de E2E Testing** [x]
    *   **Acci√≥n**:
        *   Actualizar `test/docker/codeaudit/codeaudit_e2e.sh` para levantar el stack completo con compose y probar el flujo: Upload -> Queue -> Worker (Semgrep) -> Result -> DB Verify.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 1)

*   **Tarea 3.3: Investigaci√≥n e Implementaci√≥n de Infraestructura LLM** [x]
    *   **Contexto**: El proyecto usa modelo `securetag-ai-agent:latest` en Ollama localmente.
    *   **Acci√≥n**:
        *   Investigar opciones de despliegue: Docker local (Ollama containerizado), DigitalOcean GPU Droplets, RunPod.io.
        *   Crear an√°lisis comparativo de costos, requisitos t√©cnicos, latencia y escalabilidad.
        *   Recomendar mejor opci√≥n para desarrollo y producci√≥n.
        *   Implementar soluci√≥n recomendada (agregar a `docker-compose.yml` o documentar configuraci√≥n externa).
    *   **Archivos clave**: `docker-compose.yml`, documento de investigaci√≥n en `docs/`.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 2)
    *   **Evidencia**: `EVIDENCE_Infra_2_2025-11-19.md`
    *   **Decisi√≥n**: Docker Local (desarrollo) + RunPod Serverless (producci√≥n)

*   **Tarea 3.4: Preparaci√≥n para Despliegue** [x]
    *   **Acci√≥n**:
        *   ‚úÖ Configurar CI/CD (GitHub Actions).
        *   ‚úÖ Gesti√≥n de secretos para producci√≥n.
        *   ‚úÖ Scripts de despliegue para DigitalOcean/RunPod.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 3-4)
    *   **Evidencia**: `EVIDENCE_Infra_3_2025-11-28.md`, `EVIDENCE_Infra_4_2025-12-01.md`

*   **Tarea 3.5: Integraci√≥n de Entornos (DO + RunPod)** [ ]
    *   **Contexto**: El Worker en DigitalOcean necesita consumir el LLM en RunPod.
    *   **Acci√≥n**:
        *   Actualizar scripts de despliegue para inyectar `OLLAMA_HOST` din√°mico.
        *   Documentar flujo de conexi√≥n.
        *   Verificar conexi√≥n end-to-end.
    *   **Estado**: üîÑ En Progreso
    *   **Prioridad**: Alta

### üü£ Track 4: Fine-tuning & Machine Learning (Agente "Fine-tuning")
**Objetivo**: Generar datasets de alta calidad desde fuentes externas (PDFs, web) y entrenar el modelo LLM para mejorar su rendimiento.

> **Modelo actual**: `securetag-v1` basado en Llama 3.1 8B (fine-tuned)
> **Portabilidad**: Los datasets usan formatos est√°ndar (JSONL) para permitir entrenamiento en otros modelos futuros.

*   **Tarea 4.1: Estrategia de Datos y Extracci√≥n** [x]
    *   **Acci√≥n**:
        *   Definir esquema de datos para fine-tuning (Input: Hallazgo/Contexto, Output: An√°lisis/Recomendaci√≥n).
        *   Implementar scripts para extraer datos de fuentes estructuradas (NIST, MITRE, OWASP).
        *   Generar dataset inicial en formato JSONL.
    *   **Archivos clave**: `scripts/extract_from_web.py`, `scripts/extract_from_pdf.py`, `datasets/raw/`.
    *   **Nota de portabilidad**: El formato JSONL debe ser compatible con Hugging Face, Ollama, LLaMA Factory, y Axolotl para facilitar migraci√≥n a otros modelos.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 1-2)
    *   **Evidencia**: `EVIDENCE_Finetuning_1_2025-11-20.md`, `EVIDENCE_Finetuning_2_2025-11-21.md`

*   **Tarea 4.2: Preparaci√≥n de Dataset y Entrenamiento** [x]
    *   **Acci√≥n**:
        *   Generado dataset h√≠brido (Tier 0 + Tier 1 + HuggingFace).
        *   Entrenado Llama 3.1 8B en RunPod (2x H100).
        *   Resultado: Modelo `securetag-v1` validado cualitativamente.
    *   **Estado**: ‚úÖ Completado (Iteraci√≥n 3-4)
    *   **Evidencia**: `EVIDENCE_Finetuning_3_2025-11-23.md`, `EVIDENCE_Finetuning_4_Completion.md`

*   **Tarea 4.3: Pipeline de Entrenamiento** [x]
    *   **Estado**: ‚úÖ Completado en Iteraci√≥n 3/4.

*   **Tarea 4.4: Evaluaci√≥n y Validaci√≥n** [x]
    *   **Estado**: ‚úÖ Validaci√≥n manual "A/B testing" completada. Modelo aprobado para uso.

## üìÖ Plan de Ejecuci√≥n Secuencial (Coordinaci√≥n)

Aunque los agentes trabajan en paralelo, hay hitos de sincronizaci√≥n:

1.  **Fase 1: Cimientos (Infra + DB)** [x]
    *   *Agente Infra*: Crea `docker-compose.yml` y asegura que la BD levante con el esquema correcto.
    *   *Agente Server*: Verifica conexi√≥n a BD desde contenedor App.

2.  **Fase 2: Migraci√≥n a DB-Only (Server)** [x]
    *   *Agente Server*: Elimina c√≥digo de archivos JSON. Implementa endpoints puros SQL.

3.  **Fase 3: Robustez del Worker (Worker)** [x]
    *   *Agente Worker*: Implementa retries y mejora el logging de `tool_execution`.

4.  **Fase 4: Integraci√≥n LLM & Logs (Todos)** [x]
    *   *Agente Worker*: Integra llamadas al LLM local (Ollama) para analizar hallazgos y guarda el par (Hallazgo, An√°lisis) en BD para el dataset.
    *   *Agente Fine-tuning*: Entrena modelo `securetag-v1` con dataset generado.

5.  **Fase 5: Autenticaci√≥n y Multi-tenancy (Server)** [x]
    *   *Agente Server*: Implementa API Keys y aislamiento por tenant.

6.  **Fase 6: Preparaci√≥n para Producci√≥n (Infra)** [x]
    *   *Agente Infra*: CI/CD, gesti√≥n de secretos, scripts de despliegue.

7.  **Fase 7: Integraci√≥n Final (Infra)** [ ] üîÑ SIGUIENTE
    *   *Agente Infra*: Conectar DigitalOcean con RunPod.

## üìù Notas para los Agentes
*   **Documentaci√≥n**: Leer siempre `docs/SECURETAG_SAAS_PLAN.md` antes de tocar c√≥digo cr√≠tico.
*   **Testing**: Cada cambio debe verificarse con `docker-compose up` y una prueba de flujo completa (subir archivo, verificar que se procesa).
*   **Base de Datos**: Asumir que el esquema ya existe (definido en `docs/Arquitectura...`), pero si faltan columnas para m√©tricas/logs, proponer `ALTER TABLE`.

## üöÄ Siguientes Pasos Inmediatos

### Prioridad Alta
1.  **Server Agent**: Completar Tarea 1.3 (Autenticaci√≥n y Multi-tenancy)
    *   Crear tablas `tenants` y `api_keys`
    *   Implementar middleware de autenticaci√≥n
    *   Asegurar aislamiento por `tenant_id`

### Prioridad Media
2.  **Infra Agent**: Iniciar Tarea 3.4 (Preparaci√≥n para Despliegue)
    *   Configurar GitHub Actions para CI/CD
    *   Documentar gesti√≥n de secretos
    *   Crear scripts de despliegue

### Backlog
3.  **Worker Agent**: Optimizaci√≥n de prompts LLM basado en feedback real
4.  **Fine-tuning Agent**: Evaluaci√≥n automatizada a gran escala con `evaluate_models.py`

## üìä Resumen de Progreso

| Fase | Tareas Completadas | Tareas Pendientes | Progreso |
|------|-------------------|-------------------|----------|
| **Fase 1: Cimientos** | 3/3 | 0/3 | 100% ‚úÖ |
| **Fase 2: DB-Only** | 2/2 | 0/2 | 100% ‚úÖ |
| **Fase 3: Robustez Worker** | 3/3 | 0/3 | 100% ‚úÖ |
| **Fase 4: LLM Integration** | 2/2 | 0/2 | 100% ‚úÖ |
| **Fase 5: Auth & Multi-tenancy** | 1/1 | 0/1 | 100% ‚úÖ |
| **Fase 6: Producci√≥n** | 1/1 | 0/1 | 100% ‚úÖ |
| **Fase 7: Integraci√≥n Final** | 0/1 | 1/1 | 0% üîÑ |

**Progreso Total**: 12/13 tareas completadas (92%)

---

**√öltima actualizaci√≥n**: 2025-11-27
**Supervisor**: Agente Supervisor
**Pr√≥xima revisi√≥n**: Al completar Autenticaci√≥n en Server
