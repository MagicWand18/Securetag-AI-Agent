# Plan de ImplementaciÃ³n: IntegraciÃ³n de Exploit-DB (Tarea 10.3)

**Autor**: Agente Fine-tuning  
**Fecha**: 2025-12-18  
**Objetivo**: Enriquecer el dataset de entrenamiento con cÃ³digo real de exploits verificados de Exploit-DB, orientados a la generaciÃ³n ofensiva y pruebas de seguridad (Red Teaming).

---

## 1. Estrategia de Datos

### 1.1 Enfoque: "Reverse Q&A"
A diferencia de los documentos de texto donde extraemos conocimiento declarativo (QuÃ© es X?), con los exploits usaremos un enfoque de **IngenierÃ­a Inversa de IntenciÃ³n**:
*   **Input**: CÃ³digo del Exploit + Metadata (CVE, Plataforma, Tipo).
*   **Task**: El LLM (GPT-5.1) analizarÃ¡ el cÃ³digo y generarÃ¡ la **Solicitud del Usuario** que motivarÃ­a ese resultado.
*   **Output**: Pares `User` -> `Assistant` donde el asistente entrega el exploit funcional o una prueba de concepto (PoC).

### 1.2 Criterios de Calidad (Filtrado)
Para asegurar la mÃ¡xima calidad y seguridad del dataset:
1.  **Verified Only**: Solo exploits marcados como `verified="True"` en Exploit-DB.
2.  **Platform Focus**: Prioridad a `webapps`, `remote`, `local` (Linux/Windows).
3.  **Content Integrity**: Se mantendrÃ¡ el cÃ³digo original, eliminando solo headers administrativos irrelevantes.

---

## 2. ImplementaciÃ³n por Fases

### ðŸŸ¢ Fase 1: AdquisiciÃ³n de Datos (Raw Data)
**Script**: `scripts/finetuning/download_exploitdb.sh`
*   Clonar el repositorio oficial de GitLab (`gitlab.com/exploit-database/exploitdb`).
*   UbicaciÃ³n: `sources/exploitdb/`.
*   Asegurar que `files_exploits.csv` (el Ã­ndice maestro) estÃ© presente.

### ðŸŸ¢ Fase 2: ExtracciÃ³n y Filtrado
**Script**: `scripts/finetuning/extract_exploitdb.py`
*   Leer `files_exploits.csv`.
*   Filtrar por `verified`.
*   Iterar sobre los archivos fÃ­sicos.
*   Generar un archivo estructurado: `datasets/raw/json_exploitdb.json`.
    *   Estructura por item: `{ "id": "EDB-ID", "cve": "CVE-XXXX", "platform": "web", "code": "..." }`.

### ðŸŸ¢ Fase 3: Procesamiento de Chunks
**Script**: `scripts/finetuning/process_exploitdb.py`
*   **Diferencia clave**: No usar `process_chunks.py` estÃ¡ndar (que concatena texto).
*   Crear un script dedicado que respete la unidad lÃ³gica: **1 Exploit = 1 Chunk**.
*   Si el exploit excede el tamaÃ±o de contexto (muy raro), se truncarÃ¡ o dividirÃ¡ lÃ³gicamente, pero no se mezclarÃ¡n exploits.
*   Output: `datasets/processed/json_exploitdb_chunks.json`.

### ðŸŸ¢ Fase 4: GeneraciÃ³n de Data SintÃ©tica (Q&A)
**Script**: `scripts/finetuning/generate_qa.py` (Adaptado)
*   Modificar el script existente para detectar chunks de origen `exploitdb`.
*   **Prompt Especializado (Offensive)**:
    *   Rol: "Experto en Red Teaming y Desarrollo de Exploits".
    *   Objetivo: Generar prompts de usuario como: *"Escribe un script en Python para explotar CVE-2023-XXXX..."* o *"Necesito un PoC para validar una inyecciÃ³n SQL en..."*.
    *   Guardrails: Incluir disclaimer Ã©tico en la respuesta del asistente.

### ðŸŸ¢ Fase 5: ConsolidaciÃ³n y DocumentaciÃ³n
*   Integrar los nuevos pares al dataset maestro.
*   Generar documento de evidencia: `EVIDENCE_Finetuning_5_ExploitDB.md`.

---

## 3. Estructura de Archivos Resultante

```text
securetag-agent/
â”œâ”€â”€ scripts/finetuning/
â”‚   â”œâ”€â”€ download_exploitdb.sh       # Nuevo
â”‚   â”œâ”€â”€ extract_exploitdb.py        # Nuevo
â”‚   â”œâ”€â”€ process_exploitdb.py        # Nuevo
â”‚   â””â”€â”€ generate_qa.py              # Modificado
â”œâ”€â”€ sources/
â”‚   â””â”€â”€ exploitdb/                  # Repo clonado
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ raw/json_exploitdb.json
â”‚   â””â”€â”€ processed/json_exploitdb_chunks.json
â””â”€â”€ docs/
    â””â”€â”€ .../PLAN_ExploitDB_Implementation.md
```
