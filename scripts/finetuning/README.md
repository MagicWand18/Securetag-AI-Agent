# Pipeline de Extracci√≥n de Datos para Fine-tuning

Este directorio contiene scripts para extraer datos de m√∫ltiples formatos (JSON, Markdown, XML), procesarlos y generar datasets en formato JSONL para fine-tuning del modelo `securetag-ai-agent`.

## üìã Requisitos

### Instalaci√≥n

```bash
# Crear entorno virtual (recomendado)
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### Prerequisitos

- **Python 3.8+**
- **Gemini API Key** configurada en `.env` del proyecto ra√≠z
  ```bash
  export GOOGLE_API_KEY='tu-api-key'
  ```

## üöÄ Uso

### Pipeline Completo

Ejecuta los scripts en este orden:

#### 1. Extracci√≥n de JSON (NIST, MITRE, ASVS)

```bash
python extract_json.py
```

**Procesa**:
- `NIST_SP-800-53_rev5_catalog.json` - Controles de seguridad NIST (formato OSCAL)
- `MITRE ATT&CK` - T√©cnicas de ataque (Enterprise, Mobile, ICS)
- `OWASP_Application_Security_Verification_Standard_5.0.0_en.flat.json` - Requisitos ASVS

**Output**: `../../datasets/raw/json_extracts.json`

#### 2. Extracci√≥n de Markdown (OWASP Guides)

```bash
python extract_markdown.py
```

**Procesa** (cada carpeta se consolida en un JSON):
- `masvs/` - Mobile Application Security Verification Standard
- `mastg/` - Mobile Application Security Testing Guide
- `cheatsheets owasp/` - OWASP Cheat Sheets
- `Web Application Security Testing/` - WSTG
- `OWASP Top 10 Proactive Controls/`

**Outputs**: 
- `../../datasets/raw/markdown_masvs.json`
- `../../datasets/raw/markdown_mastg.json`
- `../../datasets/raw/markdown_cheatsheets_owasp.json`
- etc.

#### 3. Extracci√≥n de XML (CWE)

```bash
python extract_xml.py
```

**Procesa**:
- `CWE Software Development.xml` - Debilidades de desarrollo
- `CWE Hardware Design.xml` - Debilidades de hardware

**Output**: `../../datasets/raw/xml_cwe_extracts.json`

#### 4. Procesamiento de Chunks

```bash
python process_chunks.py
```

**Funci√≥n**:
- Combina todos los extracts (JSON, Markdown, XML)
- Divide textos largos en chunks de 512 tokens
- Elimina duplicados
- Normaliza el texto

**Output**: `../../datasets/processed/chunks.json`

#### 5. Generaci√≥n de Q&A con Gemini

```bash
# IMPORTANTE: GOOGLE_API_KEY debe estar configurada
python generate_qa.py
```

**Funci√≥n**:
- Usa Gemini 2.0 Flash para generar 3 preguntas por chunk
- Valida calidad de Q&A
- Genera pares pregunta-respuesta en espa√±ol

**Output**: `../../datasets/processed/qa_pairs.json`

#### 6. Conversi√≥n a JSONL

```bash
python convert_to_jsonl.py
```

**Outputs**:
- `../../datasets/final/train.jsonl` (80% de los datos)
- `../../datasets/final/validation.jsonl` (20% de los datos)
- `../../datasets/final/dataset_stats.json` (estad√≠sticas)

## ‚öôÔ∏è Configuraci√≥n

Edita `config.env` para ajustar par√°metros:

```env
# Gemini (usa GOOGLE_API_KEY del .env ra√≠z)
GEMINI_MODEL=gemini-2.0-flash-exp

# Procesamiento
MAX_CHUNK_TOKENS=512
CHUNK_OVERLAP_TOKENS=50
QA_PAIRS_PER_CHUNK=3
```

## üìÅ Estructura de Datos

```
datasets/
‚îú‚îÄ‚îÄ sources/           # Fuentes originales
‚îÇ   ‚îú‚îÄ‚îÄ json/         # NIST OSCAL, MITRE ATT&CK, OWASP ASVS
‚îÇ   ‚îú‚îÄ‚îÄ markdown/     # OWASP guides (masvs, mastg, cheatsheets, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ xml/          # CWE weaknesses
‚îÇ   ‚îî‚îÄ‚îÄ pdfs/         # PDFs adicionales (ISO 27001, PCI-DSS, etc.)
‚îú‚îÄ‚îÄ raw/              # Datos extra√≠dos
‚îÇ   ‚îú‚îÄ‚îÄ json_extracts.json
‚îÇ   ‚îú‚îÄ‚îÄ markdown_*.json (uno por carpeta)
‚îÇ   ‚îî‚îÄ‚îÄ xml_cwe_extracts.json
‚îú‚îÄ‚îÄ processed/        # Datos procesados
‚îÇ   ‚îú‚îÄ‚îÄ chunks.json
‚îÇ   ‚îî‚îÄ‚îÄ qa_pairs.json
‚îî‚îÄ‚îÄ final/            # Datasets finales
    ‚îú‚îÄ‚îÄ train.jsonl
    ‚îú‚îÄ‚îÄ validation.jsonl
    ‚îî‚îÄ‚îÄ dataset_stats.json
```

## üìä Formato del Dataset

Cada l√≠nea en `train.jsonl` y `validation.jsonl`:

```json
{
  "instruction": "¬øQu√© requiere el control AC-2 de NIST SP 800-53?",
  "input": "",
  "output": "El control AC-2 (Account Management) requiere que las organizaciones...",
  "metadata": {
    "source": "NIST SP 800-53 Rev 5",
    "id": "AC-2",
    "chunk_index": 0
  }
}
```

Este formato es compatible con:
- Hugging Face Datasets
- Ollama fine-tuning
- LLaMA Factory
- Axolotl
- Unsloth

## üîß Troubleshooting

### Error: "GOOGLE_API_KEY no est√° configurada"

```bash
# Verificar que la API key est√© en el .env ra√≠z
cat ../../.env | grep GOOGLE_API_KEY

# Si no est√°, agregarla
echo "GOOGLE_API_KEY=tu-api-key" >> ../../.env
```

### Error: "No se encontraron archivos JSON/Markdown/XML"

Verifica que los archivos est√©n en las carpetas correctas:
```bash
ls -lh ../../datasets/sources/json/
ls -lh ../../datasets/sources/markdown/
ls -lh ../../datasets/sources/xml/
```

### Pocos datos generados

- Verifica que todos los archivos fuente est√©n presentes
- Ajusta `QA_PAIRS_PER_CHUNK` en `config.env` (por defecto: 3)
- Revisa los logs de cada script para ver qu√© se proces√≥

## üìà Fuentes de Datos

### JSON (63 MB total)
- **NIST SP 800-53 Rev 5** (10 MB) - ~1000 controles de seguridad
- **MITRE ATT&CK Enterprise** (43 MB) - ~600 t√©cnicas
- **MITRE ATT&CK Mobile** (4 MB) - ~100 t√©cnicas
- **MITRE ATT&CK ICS** (3 MB) - ~80 t√©cnicas
- **OWASP ASVS 5.0** (160 KB) - ~200 requisitos

### Markdown (525 archivos)
- **MASVS** - Mobile Application Security Verification Standard
- **MASTG** - Mobile Application Security Testing Guide
- **OWASP Cheat Sheets** - 107 hojas de referencia
- **WSTG** - Web Security Testing Guide
- **OWASP Top 10 Proactive Controls**

### XML (7 MB total)
- **CWE Software Development** (5.8 MB) - ~800 debilidades
- **CWE Hardware Design** (1.5 MB) - ~200 debilidades

### PDFs (13 MB total)
- **ISO 27001:2022** (476 KB)
- **PCI-DSS v4.0.1** (5.1 MB)
- **NIST SP 800-61r2** (1.5 MB) - Incident Response
- **NIST SP 800-53r5** (5.8 MB) - Security Controls (PDF backup)

## üìù Notas

### ¬øPor qu√© no TOON?

Inicialmente se consider√≥ usar TOON (Token-Oriented Object Notation) para reducir tokens, pero se decidi√≥ usar **JSON optimizado** porque:
- Gemini no soporta TOON nativamente (requerir√≠a incluirlo en cada prompt)
- JSON con solo campos esenciales es m√°s eficiente
- TOON est√° dise√±ado para inferencia, no para datasets de entrenamiento

### Optimizaci√≥n de Tokens

Los scripts extraen **solo campos esenciales** para Q&A:
- ‚úÖ T√≠tulo, descripci√≥n, gu√≠as, mitigaciones
- ‚ùå Metadata innecesaria (fechas, autores, versiones, IDs internos)

### Consolidaci√≥n de Markdown

Cada carpeta de markdown se consolida en **un solo JSON** para facilitar el procesamiento y mantener el contexto relacionado junto.

## üìö Pr√≥ximos Pasos

Una vez generados los datasets:

1. **Fine-tuning local con Ollama** (si aplica)
2. **Fine-tuning en RunPod con QLoRA**
3. **Evaluaci√≥n del modelo fine-tuned**
4. **Iteraci√≥n con m√°s datos**
